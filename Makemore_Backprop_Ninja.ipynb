{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "E3KSRgMtjlVl",
        "aPADO1juj8y7",
        "R8HajZHcsSO8",
        "njZev3hvxmLs",
        "hjvUpnDhy4C1"
      ],
      "authorship_tag": "ABX9TyMjOM+9A3pO8bi4CIOh0DBJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunRise9551/Building_Makemore/blob/main/Makemore_Backprop_Ninja.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "Ybz5KzOHsd2U"
      },
      "outputs": [],
      "source": [
        "# there no change change in the first several cells from last lecture"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt # for making figures\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "h7iXnSaFsgKP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download the names.txt file from github\n",
        "!wget https://raw.githubusercontent.com/karpathy/makemore/master/names.txt"
      ],
      "metadata": {
        "id": "x6GhEWW18aCS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7894c5f1-7c80-4cc8-dc4c-d11d6494b3ea"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-18 11:46:26--  https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228145 (223K) [text/plain]\n",
            "Saving to: ‘names.txt.3’\n",
            "\n",
            "\rnames.txt.3           0%[                    ]       0  --.-KB/s               \rnames.txt.3         100%[===================>] 222.80K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2023-09-18 11:46:26 (53.7 MB/s) - ‘names.txt.3’ saved [228145/228145]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "klmu3ZG08PPr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71ee6c09-a487-451b-d32e-35a41931eb3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32033\n",
            "15\n",
            "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
          ]
        }
      ],
      "source": [
        "# read in all the words\n",
        "words = open('names.txt', 'r').read().splitlines()\n",
        "print(len(words))\n",
        "print(max(len(w) for w in words))\n",
        "print(words[:8])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BCQomLE_8PPs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2514232-8ab3-42e3-f7a9-b4924bfc862c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
            "27\n"
          ]
        }
      ],
      "source": [
        "# build the vocabulary of characters and mappings to/from integers\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "vocab_size = len(itos)\n",
        "print(itos)\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "V_zt2QHr8PPs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14c19aba-bddd-4ec0-a263-b250ca13a4c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([182625, 3]) torch.Size([182625])\n",
            "torch.Size([22655, 3]) torch.Size([22655])\n",
            "torch.Size([22866, 3]) torch.Size([22866])\n"
          ]
        }
      ],
      "source": [
        "# build the dataset\n",
        "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
        "\n",
        "def build_dataset(words):\n",
        "  X, Y = [], []\n",
        "\n",
        "  for w in words:\n",
        "    context = [0] * block_size\n",
        "    for ch in w + '.':\n",
        "      ix = stoi[ch]\n",
        "      X.append(context)\n",
        "      Y.append(ix)\n",
        "      context = context[1:] + [ix] # crop and append\n",
        "\n",
        "  X = torch.tensor(X)\n",
        "  Y = torch.tensor(Y)\n",
        "  print(X.shape, Y.shape)\n",
        "  return X, Y\n",
        "\n",
        "import random\n",
        "random.seed(42)\n",
        "random.shuffle(words)\n",
        "n1 = int(0.8*len(words))\n",
        "n2 = int(0.9*len(words))\n",
        "\n",
        "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
        "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
        "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eg20-vsg8PPt"
      },
      "outputs": [],
      "source": [
        "# ok biolerplate done, now we get to the action:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MJPU8HT08PPu"
      },
      "outputs": [],
      "source": [
        "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
        "def cmp(s, dt, t):\n",
        "  ex = torch.all(dt == t.grad).item()\n",
        "  app = torch.allclose(dt, t.grad)\n",
        "  maxdiff = (dt - t.grad).abs().max().item()\n",
        "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZlFLjQyT8PPu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0b16a56-3643-458e-c138-c01b90a85412"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4137\n"
          ]
        }
      ],
      "source": [
        "n_embd = 10 # the dimensionality of the character embedding vectors\n",
        "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
        "# Layer 1\n",
        "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
        "b1 = torch.randn(n_hidden,                        generator=g) * 0.1 # using b1 just for fun, it's useless because of BN\n",
        "# Layer 2\n",
        "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
        "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
        "# BatchNorm parameters\n",
        "bngain = torch.randn((1, n_hidden), generator=g)*0.1 + 1.0\n",
        "bnbias = torch.randn((1, n_hidden), generator=g)*0.1\n",
        "\n",
        "# Note: I am initializating many of these parameters in non-standard ways\n",
        "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
        "# implementation of the backward pass.\n",
        "\n",
        "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
        "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QY-y96Y48PPv"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "n = batch_size # a shorter variable also, for convenience\n",
        "# construct a minibatch\n",
        "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
        "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8ofj1s6d8PPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "195254f5-adaf-458f-c7dc-a70d9f30fbac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.5571, grad_fn=<NegBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
        "\n",
        "emb = C[Xb] # embed the characters into vectors\n",
        "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
        "# Linear layer 1\n",
        "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
        "# BatchNorm layer\n",
        "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
        "bndiff = hprebn - bnmeani\n",
        "bndiff2 = bndiff**2\n",
        "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
        "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
        "bnraw = bndiff * bnvar_inv\n",
        "hpreact = bngain * bnraw + bnbias\n",
        "# Non-linearity\n",
        "h = torch.tanh(hpreact) # hidden layer\n",
        "# Linear layer 2\n",
        "logits = h @ W2 + b2 # output layer\n",
        "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
        "logit_maxes = logits.max(1, keepdim=True).values\n",
        "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
        "counts = norm_logits.exp()\n",
        "counts_sum = counts.sum(1, keepdims=True)\n",
        "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
        "probs = counts * counts_sum_inv\n",
        "logprobs = probs.log()\n",
        "loss = -logprobs[range(n), Yb].mean()\n",
        "\n",
        "# PyTorch backward pass\n",
        "for p in parameters:\n",
        "  p.grad = None\n",
        "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
        "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
        "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
        "         embcat, emb]:\n",
        "  t.retain_grad()\n",
        "loss.backward()\n",
        "loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Derivatives"
      ],
      "metadata": {
        "id": "OjRCjslUjitc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dloss/dlogprobs"
      ],
      "metadata": {
        "id": "E3KSRgMtjlVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Yb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8V7vEMQ_h5x7",
        "outputId": "9e95798c-eaa1-4145-cde3-cc14d8a6fd5c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1,  0, 25, 12,  9,  9,  0,  0, 13, 25, 13, 18, 25, 14, 12,  9, 12, 15,\n",
              "         5, 15, 14,  0,  5,  1, 15, 25, 20,  8,  1,  1, 15,  0])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "-logprobs[range(n), Yb]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-FCH0Ksh7wj",
        "outputId": "c0adeee1-c52b-4d82-9afb-b5e470c5215d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3.8106, 2.6852, 3.5044, 3.5740, 3.7504, 3.2781, 3.0362, 3.9446, 3.4031,\n",
              "        2.9343, 3.4031, 4.1493, 3.0322, 3.7628, 2.9034, 3.0381, 3.2786, 4.1927,\n",
              "        3.8432, 3.6620, 3.3188, 2.9225, 3.3225, 4.2062, 3.5622, 4.0472, 3.8938,\n",
              "        3.4679, 4.4514, 4.3026, 3.4206, 3.7267], grad_fn=<NegBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    loss = -logprobs[range(n), Yb].mean()\n",
        "    loss = - (a + b + c) / 3\n",
        "    loss = -1/3a +-1/3b +-1/3c\n",
        "    \n",
        "    dlogprobs = ???\n",
        "\n",
        "    dloss/da = -1/3\n",
        "    dloss/db = -1/3\n",
        "    dloss/dc = -1/3\n",
        "\n",
        "    dlogprobs = -1/n"
      ],
      "metadata": {
        "id": "xELLFfGBkDzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dlogprobs = torch.zeros_like(logprobs)\n",
        "dlogprobs[range(n), Yb] = -1.0/n\n",
        "cmp('logprobs', dlogprobs, logprobs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xKD-wVOkPDj",
        "outputId": "852cbdd4-ed02-44ea-b1e8-5f27ab74dab9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dprobs"
      ],
      "metadata": {
        "id": "aPADO1juj8y7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    logprobs = probs.log()\n",
        "\n",
        "    dprobs = ???\n",
        "\n",
        "    dprobs = (Local) * (Ouput)\n",
        "    dprobs = (log) * (dlogprobs)\n",
        "    dprobs = (1/probs) * (dlogprobs)\n",
        "\n"
      ],
      "metadata": {
        "id": "QZCXFIRcqaxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dprobs = (1/probs) * (dlogprobs)\n",
        "cmp('probs', dprobs, probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7og4GWtqMWr",
        "outputId": "15948f41-f053-4f7a-9e9a-1de0199e6872"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dcounts_sum_inv"
      ],
      "metadata": {
        "id": "R8HajZHcsSO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "probs = counts * counts_sum_inv"
      ],
      "metadata": {
        "id": "VFb3nw-1uzvD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counts.shape, counts_sum_inv.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTIiMGvFu1dC",
        "outputId": "bc036ec3-4a66-47ad-a47f-d33f0f6202a5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 27]), torch.Size([32, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# c = a * b, but with tensors:\n",
        "# a[3x2] * b[3,1] --->\n",
        "# a11*b1 a12*b1 a13*b1\n",
        "# a21*b2 a22*b2 a23*b2\n",
        "# a31*b3 a23*b3 a33*b3\n",
        "# c[3x3]"
      ],
      "metadata": {
        "id": "Ie83rQMOu4nr"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    probs = counts * counts_sum_inv\n",
        "\n",
        "    dcounts_sum_inv = ???\n",
        "\n",
        "    dcounts_sum_inv = (Local) * (Output)\n",
        "    dcounts_sum_inv = (counts) * (dprobs) <-- Local for multiplication is another data(which is 'counts' here)\n",
        "    dcounts_sum_inv = ((counts) * (dprobs)).sum(1, keepdim=True)"
      ],
      "metadata": {
        "id": "3fG95GXyt9Bz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dcounts_sum_inv = ((counts) * (dprobs)).sum(1, keepdim=True)\n",
        "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhoGLqAhsR0C",
        "outputId": "f7543004-3ff1-422a-931d-a4c56301cc61"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dcounts (1st Branch)"
      ],
      "metadata": {
        "id": "njZev3hvxmLs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    probs = counts * counts_sum_inv\n",
        "\n",
        "    dcounts = ???\n",
        "\n",
        "    dcounts = (Local) * (Output)\n",
        "    dcounts = (counts_sum_inv) * (dprobs)"
      ],
      "metadata": {
        "id": "_juApR0mxsb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dcounts = (counts_sum_inv) * (dprobs)"
      ],
      "metadata": {
        "id": "jbrb8N3_x5BH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cannot check yet, because:"
      ],
      "metadata": {
        "id": "-NLTSyfy3Pw0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "A67_EPgS3Swj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dcounts_sum"
      ],
      "metadata": {
        "id": "hjvUpnDhy4C1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counts_sum_inv = counts_sum**-1"
      ],
      "metadata": {
        "id": "aBGtO2IBzGn0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    counts_sum_inv = counts_sum**-1\n",
        "\n",
        "    dcounts_sum = ???\n",
        "\n",
        "    counts_sum**-1\n",
        "    = a**-1\n",
        "    = 1/a\n",
        "    = 1/a^2\n",
        "\n",
        "    dcounts_sum = (Local) * (Output)\n",
        "    dcounts_sum = (1/counts_sum**2) * (dcounts_sum_inv)"
      ],
      "metadata": {
        "id": "ZyyXEr-ozIt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dcounts_sum = (-counts_sum**-2) * (dcounts_sum_inv)\n",
        "dcounts_sum = (-1/counts_sum**2) * (dcounts_sum_inv)\n",
        "cmp('counts_sum', dcounts_sum, counts_sum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDkDCQiC2pQE",
        "outputId": "e1edab4f-5e97-4776-e869-16cc3b633ec2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dcounts (2nd Branch)"
      ],
      "metadata": {
        "id": "VN62Ugev6G0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counts_sum = counts.sum(1, keepdims=True)"
      ],
      "metadata": {
        "id": "lcfA63Jp6JPN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code: Summing up all the counts, in rows"
      ],
      "metadata": {
        "id": "yJ2HSx-z_ltd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# counts_sum = b1(= a11 + a12 + a13)\n",
        "\n",
        "# a11 a12 a13 ---> b1(= a11 + a12 + a13)\n",
        "# a21 a22 a23 ---> b2(= a21 + a22 + a23)\n",
        "# a31 a23 a33 ---> b3(= a31 + a32 + a33)"
      ],
      "metadata": {
        "id": "hxcCgj2o6Mss"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We now have the derivatives of loss with respect to b1, b2, b3, ...\n",
        "\n",
        "- We want the derivatives of loss with respect to a11, a12, a13, a21, ...\n",
        "\n",
        "- In other way, how do b1, b2 depends on a11, etc."
      ],
      "metadata": {
        "id": "u2IkOqcd9jDl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- b1 will only depends on (a11 + a12 + a13)\n",
        "- Local derivative for Addition is always 1"
      ],
      "metadata": {
        "id": "INgsC9Nl-qku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    counts_sum = counts.sum(1, keepdims=True)\n",
        "\n",
        "    dcounts = ???\n",
        "\n",
        "    dcounts = (Local) * (Input)\n",
        "    dcounts = (torch.ones_like(counts)) * (dcounts_sum)"
      ],
      "metadata": {
        "id": "MP5IUb5G8RUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dcounts += (torch.ones_like(counts)) * (dcounts_sum)\n",
        "cmp('counts', dcounts, counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9LXNaK_8O9k",
        "outputId": "0267fbd1-0b54-48a9-a5bc-f3b9255764d2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dnorms_logits"
      ],
      "metadata": {
        "id": "PiUo3LoGHWrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counts = norm_logits.exp()"
      ],
      "metadata": {
        "id": "PZJakyWfHfMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    counts = norm_logits.exp()\n",
        "\n",
        "    dnorm_logits = ???\n",
        "\n",
        "    dnorm_logits = (Local) * (Input)\n",
        "    dnorm_logits = (norm_logits.exp()) * (dcounts)\n",
        "    dnorm_logits = (counts) * (dcounts)"
      ],
      "metadata": {
        "id": "tRFsd6S3HnFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dnorm_logits = (counts) * (dcounts)\n",
        "cmp('norm_logits', dnorm_logits, norm_logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTkeAXfhI1N1",
        "outputId": "9e6b7610-dea7-4c07-ac7f-68bebc9d70dc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dlogit_maxes"
      ],
      "metadata": {
        "id": "sPRK9gqaJa_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "norm_logits = logits - logit_maxes"
      ],
      "metadata": {
        "id": "usOxcRzyJdSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "norm_logits.shape, logits.shape, logit_maxes.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3X1Z8QUNKQAO",
        "outputId": "bf3c53a9-29fa-4a19-e910-0cc8842f605b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 27]), torch.Size([32, 27]), torch.Size([32, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# c11 c12 c13 ---> a11 + a12 + a13   b1\n",
        "# c21 c22 c23 ---> a21 + a22 + a23 - b2\n",
        "# c31 c23 c33 ---> a31 + a32 + a33   b3\n",
        "\n",
        "# so e.g. c32 = a32 - b3"
      ],
      "metadata": {
        "id": "6Qx_t4uSKal8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    norm_logits = logits - logit_maxes\n",
        "         c32    =   a32  -     b3\n",
        "\n",
        "    dlogit_maxes = ???  equivalent to db3 = ???\n",
        "\n",
        "    dlogit_maxes = (Local) * (Output)\n",
        "    dlogit_maxes = (-b3) * (dnorm_logits)\n",
        "    dlogit_maxes = (-1) * (dnorm_logits)\n",
        "    dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True) <-- Sum all across row"
      ],
      "metadata": {
        "id": "HhcwQ99UJqMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True)\n",
        "cmp('logit_maxes', dlogit_maxes, logit_maxes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKr7u_gFJr_8",
        "outputId": "c1e30d85-b651-4689-fc9c-fedc07117374"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 1"
      ],
      "metadata": {
        "id": "T3vHIb_I8BDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 1: backprop through the whole thing manually,\n",
        "# backpropagating through exactly all of the variables\n",
        "# as they are defined in the forward pass above, one by one\n",
        "\n",
        "# -----------------\n",
        "# YOUR CODE HERE :)\n",
        "# -----------------\n",
        "\n",
        "cmp('logprobs', dlogprobs, logprobs)\n",
        "cmp('probs', dprobs, probs)\n",
        "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
        "cmp('counts_sum', dcounts_sum, counts_sum)\n",
        "cmp('counts', dcounts, counts)\n",
        "cmp('norm_logits', dnorm_logits, norm_logits)\n",
        "# cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
        "# cmp('logits', dlogits, logits)\n",
        "# cmp('h', dh, h)\n",
        "# cmp('W2', dW2, W2)\n",
        "# cmp('b2', db2, b2)\n",
        "# cmp('hpreact', dhpreact, hpreact)\n",
        "# cmp('bngain', dbngain, bngain)\n",
        "# cmp('bnbias', dbnbias, bnbias)\n",
        "# cmp('bnraw', dbnraw, bnraw)\n",
        "# cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
        "# cmp('bnvar', dbnvar, bnvar)\n",
        "# cmp('bndiff2', dbndiff2, bndiff2)\n",
        "# cmp('bndiff', dbndiff, bndiff)\n",
        "# cmp('bnmeani', dbnmeani, bnmeani)\n",
        "# cmp('hprebn', dhprebn, hprebn)\n",
        "# cmp('embcat', dembcat, embcat)\n",
        "# cmp('W1', dW1, W1)\n",
        "# cmp('b1', db1, b1)\n",
        "# cmp('emb', demb, emb)\n",
        "# cmp('C', dC, C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "mk-RoDXrXTT7",
        "outputId": "bf3f1225-df7e-4eae-8c3e-a135313dfcd4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-b3d747dfac40>:3: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:486.)\n",
            "  ex = torch.all(dt == t.grad).item()\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-b8e0690b157f>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'logprobs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdlogprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'probs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mcmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'counts_sum_inv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdcounts_sum_inv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts_sum_inv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mcmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'counts_sum'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdcounts_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-b3d747dfac40>\u001b[0m in \u001b[0;36mcmp\u001b[0;34m(s, dt, t)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# utility function we will use later when comparing manual gradients to PyTorch gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mapp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mmaxdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: all(): argument 'input' (position 1) must be Tensor, not bool"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AyhoG8p8mP_Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}